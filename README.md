# DNN Channel Estimation Training

> PyTorch ê¸°ë°˜ DMRS ì±„ë„ ì¶”ì •ì„ ìœ„í•œ DNN ëª¨ë¸ í›ˆë ¨ ì‹œìŠ¤í…œ

## ğŸš€ ë¹ ë¥¸ ì‹œì‘ (Vast AI)

### ğŸ¯ ì™„ì „ ìë™ ì„¤ì¹˜ (ê¶Œì¥)
```bash
# ìƒˆ Vast AI ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì´ í•œ ì¤„ë§Œ ì‹¤í–‰
curl -sSL https://raw.githubusercontent.com/joowonoil/channel-estimation-training/main/setup_vast_ai.sh | bash

# ì„¤ì¹˜ ì™„ë£Œ í›„ ë°”ë¡œ ì‹¤í–‰
python Transfer_v4.py
```

### ğŸ“‹ ìˆ˜ë™ ì„¤ì¹˜
```bash
# 1. í”„ë¡œì íŠ¸ í´ë¡  (Git LFSë¡œ ëª¨ë“  ë°ì´í„° ìë™ ë‹¤ìš´ë¡œë“œ)
git clone https://github.com/joowonoil/channel-estimation-training.git
cd channel-estimation-training

# 2. InF LoRA ì „ì´í•™ìŠµ ì‹¤í–‰
python Transfer_v4.py
```

## ğŸ“‹ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
channel-estimation-training/
â”œâ”€â”€ ğŸ“ model/                    # DNN ëª¨ë¸ ì•„í‚¤í…ì²˜
â”‚   â”œâ”€â”€ estimator.py            # ê¸°ë³¸ ì±„ë„ ì¶”ì • ëª¨ë¸
â”‚   â”œâ”€â”€ estimator_v3.py         # Adapter ê¸°ë°˜ ëª¨ë¸
â”‚   â”œâ”€â”€ estimator_v4.py         # LoRA ê¸°ë°˜ ëª¨ë¸
â”‚   â””â”€â”€ transformer.py          # Transformer êµ¬ì¡°
â”œâ”€â”€ ğŸ“ dataset/                 # ë°ì´í„°ì…‹ (Git LFS)
â”‚   â””â”€â”€ PDP_processed/          # ì²˜ë¦¬ëœ PDP ë°ì´í„°
â”œâ”€â”€ ğŸ“ config/                  # ì„¤ì • íŒŒì¼ë“¤
â”‚   â”œâ”€â”€ config.yaml             # ê¸°ë³¸ ì„¤ì •
â”‚   â””â”€â”€ config_transfer_v4.yaml # v4 ëª¨ë¸ ì„¤ì •
â”œâ”€â”€ ğŸ“ saved_model/             # í›ˆë ¨ëœ ëª¨ë¸ (Git LFS)
â””â”€â”€ ğŸ“ sample_data*/            # ìƒ˜í”Œ ë°ì´í„° (Git LFS)
```

## ğŸ”§ ëª¨ë¸ ì¢…ë¥˜

### 1. Transfer.py - ê¸°ë³¸ ëª¨ë¸
- í‘œì¤€ Transformer ê¸°ë°˜ ì±„ë„ ì¶”ì •
- ê¸°ë³¸ì ì¸ ì „ì´í•™ìŠµ ì§€ì›

### 2. Transfer_v3.py - Adapter ëª¨ë¸  
- Parameter-Efficient Fine-tuning
- Adapter ë ˆì´ì–´ë¥¼ í†µí•œ íš¨ìœ¨ì  í•™ìŠµ

### 3. Transfer_v4.py - LoRA ëª¨ë¸
- Low-Rank Adaptation (LoRA) ì ìš©
- ìµœì†Œí•œì˜ íŒŒë¼ë¯¸í„°ë¡œ ë†’ì€ ì„±ëŠ¥

## ğŸ³ Docker í™˜ê²½

### ì‚¬ì „ ì¤€ë¹„ëœ í™˜ê²½ ì‚¬ìš©
```bash
# Vast AIì—ì„œ Docker ì´ë¯¸ì§€ ì‚¬ìš©
docker pull joowonoil/channel-estimation-env:latest
docker run --gpus all -it joowonoil/channel-estimation-env:latest
```

### í¬í•¨ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬
- PyTorch 2.4.1 + CUDA 12.1
- TensorRT, ONNX ìµœì í™” ë„êµ¬
- transformers, peft (LoRA)
- ëª¨ë“  í•„ìš”í•œ ì˜ì¡´ì„± íŒ¨í‚¤ì§€

## âš¡ TensorRT ë³€í™˜

```bash
# ONNX ë° TensorRT ì—”ì§„ ìƒì„±
python tensorrt_conversion_v4.py
```

## ğŸ“Š ë°ì´í„°ì…‹

### ì±„ë„ íƒ€ì… (InF íŠ¹í™”)
- **InF (Indoor Factory)**: Los/Nlos 50000 ìƒ˜í”Œ
- ì‹¤ë‚´ ê³µì¥ í™˜ê²½ì—ì„œì˜ ì±„ë„ íŠ¹ì„±
- LoRA ì „ì´í•™ìŠµì„ í†µí•œ íš¨ìœ¨ì  ëª¨ë¸ ì ì‘

### ë°ì´í„° í˜•ì‹
- **PDP íŒŒì¼**: `*.mat` (MATLAB í˜•ì‹)
- **ìƒ˜í”Œ ë°ì´í„°**: `*.npy`, `*.npz` (NumPy í˜•ì‹)
- **ëª¨ë¸ íŒŒì¼**: `*.pt` (PyTorch í˜•ì‹)

## ğŸ› ï¸ ê°œë°œ í™˜ê²½ ì„¤ì •

### ë¡œì»¬ ê°œë°œ
```bash
# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# Git LFS ì„¤ì • (ì²˜ìŒ í•œ ë²ˆë§Œ)
git lfs install
```

### ì„¤ì • íŒŒì¼ ìˆ˜ì •
```bash
# ëª¨ë¸ ì„¤ì • ë³€ê²½
vim config/config_transfer_v4.yaml

# ë°ì´í„° ê²½ë¡œ, ë°°ì¹˜ í¬ê¸°, í•™ìŠµë¥  ë“± ì¡°ì • ê°€ëŠ¥
```

## ğŸ”¬ ì‹¤í—˜ ê´€ë¦¬

### Weights & Biases ì—°ë™
```bash
# Wandb ë¡œê·¸ì¸ (ì„ íƒì‚¬í•­)
wandb login

# ì‹¤í—˜ ê²°ê³¼ëŠ” ìë™ìœ¼ë¡œ wandbì— ê¸°ë¡ë¨
```

### ëª¨ë¸ ì €ì¥
- í›ˆë ¨ëœ ëª¨ë¸: `saved_model/`
- TensorRT ì—”ì§„: `tensorrt_model/`
- ì²´í¬í¬ì¸íŠ¸: ìë™ ì €ì¥

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### GPU ë©”ëª¨ë¦¬ ìµœì í™”
- ë°°ì¹˜ í¬ê¸° ì¡°ì •: `config/*.yaml`
- Mixed Precision ì§€ì›
- Gradient Checkpointing

### ì¶”ë¡  ê°€ì†í™”
- TensorRT ì—”ì§„ ë³€í™˜
- ONNX ìµœì í™”
- ë‹¤ì¤‘ GPU ì§€ì›

## ğŸ¤ ê¸°ì—¬ ë°©ë²•

1. Fork the repository
2. Create feature branch: `git checkout -b feature/new-feature`
3. Commit changes: `git commit -am 'Add new feature'`
4. Push to branch: `git push origin feature/new-feature`
5. Submit Pull Request

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ìˆìŠµë‹ˆë‹¤.

## ğŸ™‹â€â™‚ï¸ ì§€ì›

ë¬¸ì œê°€ ë°œìƒí•˜ë©´ [Issues](https://github.com/joowonoil/channel-estimation-training/issues)ì— ë“±ë¡í•´ì£¼ì„¸ìš”.

---

**ğŸ¯ ëª©í‘œ**: InF ì±„ë„ í™˜ê²½ì—ì„œ LoRA ì „ì´í•™ìŠµì„ í†µí•œ DMRS ê¸°ë°˜ 5G/6G ì±„ë„ ì¶”ì • ì„±ëŠ¥ í–¥ìƒ